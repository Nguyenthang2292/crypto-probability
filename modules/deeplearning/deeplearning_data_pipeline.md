# üìö Deep Learning Data Pipeline Documentation

## M·ª•c l·ª•c
1. [T·ªïng quan](#t·ªïng-quan)
2. [Kh·ªüi t·∫°o](#kh·ªüi-t·∫°o)
3. [Ph∆∞∆°ng th·ª©c ch√≠nh](#ph∆∞∆°ng-th·ª©c-ch√≠nh)
4. [C√°c th√†nh ph·∫ßn](#c√°c-th√†nh-ph·∫ßn)
5. [V√≠ d·ª• s·ª≠ d·ª•ng](#v√≠-d·ª•-s·ª≠-d·ª•ng)
6. [Best Practices](#best-practices)
7. [Pipeline Steps](#pipeline-steps)

---

## T·ªïng quan

`DeepLearningDataPipeline` l√† m·ªôt pipeline to√†n di·ªán ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu cho deep learning models, ƒë·∫∑c bi·ªát l√† Temporal Fusion Transformer (TFT). Pipeline n√†y cung c·∫•p:

- ‚úÖ **OHLCV Fetching** - L·∫•y d·ªØ li·ªáu t·ª´ DataFetcher v·ªõi fallback t·ª± ƒë·ªông
- ‚úÖ **Target Engineering** - Log Returns, % Change, Triple Barrier Method
- ‚úÖ **Fractional Differentiation** - ƒê·∫£m b·∫£o stationarity m√† v·∫´n gi·ªØ memory
- ‚úÖ **Technical Indicators** - T·ª± ƒë·ªông t√≠nh to√°n indicators qua IndicatorEngine
- ‚úÖ **Known-future Features** - Time-of-day, day-of-week, funding schedule
- ‚úÖ **Per-symbol Normalization** - StandardScaler per symbol ƒë·ªÉ x·ª≠ l√Ω scale differences
- ‚úÖ **Feature Selection** - T√≠ch h·ª£p FeatureSelector ƒë·ªÉ ch·ªçn top features
- ‚úÖ **Chronological Split** - Train/validation/test split v·ªõi gap ƒë·ªÉ tr√°nh data leakage

### Khi n√†o d√πng DeepLearningDataPipeline?

| M·ª•c ƒë√≠ch | D√πng Pipeline? | Ph∆∞∆°ng th·ª©c |
|----------|----------------|-------------|
| Chu·∫©n b·ªã data cho TFT | ‚úÖ C√≥ | `fetch_and_prepare()` + `split_chronological()` |
| C·∫ßn target engineering (log returns, triple barrier) | ‚úÖ C√≥ | T·ª± ƒë·ªông trong `prepare_dataframe()` |
| C·∫ßn fractional differentiation | ‚úÖ C√≥ | Set `use_fractional_diff=True` |
| C·∫ßn technical indicators | ‚úÖ C√≥ | T·ª± ƒë·ªông qua IndicatorEngine |
| C·∫ßn normalization per symbol | ‚úÖ C√≥ | T·ª± ƒë·ªông trong `_normalize_per_symbol()` |
| C·∫ßn feature selection | ‚úÖ C√≥ | T√≠ch h·ª£p FeatureSelector |
| C·∫ßn train/val/test split | ‚úÖ C√≥ | `split_chronological()` |

---

## Kh·ªüi t·∫°o

### C√∫ ph√°p

```python
from modules.deeplearning_data_pipeline import DeepLearningDataPipeline
from modules.DataFetcher import DataFetcher

# Kh·ªüi t·∫°o DataFetcher tr∆∞·ªõc
data_fetcher = DataFetcher(exchange_manager)

# Kh·ªüi t·∫°o Pipeline
pipeline = DeepLearningDataPipeline(
    data_fetcher=data_fetcher,
    use_fractional_diff=True,
    use_triple_barrier=False,
    use_feature_selection=True
)
```

### Tham s·ªë ch√≠nh

- `data_fetcher` (DataFetcher, **b·∫Øt bu·ªôc**): Instance c·ªßa DataFetcher ƒë·ªÉ l·∫•y OHLCV data
- `indicator_engine` (IndicatorEngine, **t√πy ch·ªçn**): Instance c·ªßa IndicatorEngine (t·∫°o m·ªõi n·∫øu None)
- `use_fractional_diff` (bool, **m·∫∑c ƒë·ªãnh**: `True`): C√≥ √°p d·ª•ng fractional differentiation kh√¥ng
- `fractional_diff_d` (float, **m·∫∑c ƒë·ªãnh**: `0.5`): Order c·ªßa fractional differentiation (0 < d < 1)
- `use_triple_barrier` (bool, **m·∫∑c ƒë·ªãnh**: `False`): C√≥ d√πng Triple Barrier Method kh√¥ng
- `triple_barrier_tp` (float, **m·∫∑c ƒë·ªãnh**: `0.02`): Take profit threshold (2%)
- `triple_barrier_sl` (float, **m·∫∑c ƒë·ªãnh**: `0.01`): Stop loss threshold (1%)
- `use_feature_selection` (bool, **m·∫∑c ƒë·ªãnh**: `True`): C√≥ √°p d·ª•ng feature selection kh√¥ng
- `feature_selection_method` (str, **m·∫∑c ƒë·ªãnh**: `"mutual_info"`): Ph∆∞∆°ng ph√°p feature selection
- `feature_selection_top_k` (int, **m·∫∑c ƒë·ªãnh**: `25`): S·ªë l∆∞·ª£ng features c·∫ßn ch·ªçn

### V√≠ d·ª• kh·ªüi t·∫°o

```python
from modules.deeplearning_data_pipeline import DeepLearningDataPipeline
from modules.DataFetcher import DataFetcher
from modules.ExchangeManager import ExchangeManager

# Setup
em = ExchangeManager()
data_fetcher = DataFetcher(em)

# C√°ch 1: M·∫∑c ƒë·ªãnh (fractional diff ON, triple barrier OFF, feature selection ON)
pipeline = DeepLearningDataPipeline(data_fetcher)

# C√°ch 2: T√πy ch·ªânh
pipeline = DeepLearningDataPipeline(
    data_fetcher=data_fetcher,
    use_fractional_diff=True,
    use_triple_barrier=True,  # B·∫≠t triple barrier
    triple_barrier_tp=0.03,  # 3% TP
    triple_barrier_sl=0.015,  # 1.5% SL
    use_feature_selection=True,
    feature_selection_method="boruta",
    feature_selection_top_k=30
)

# C√°ch 3: Kh√¥ng d√πng fractional diff (nhanh h∆°n)
pipeline = DeepLearningDataPipeline(
    data_fetcher=data_fetcher,
    use_fractional_diff=False
)
```

---

## Ph∆∞∆°ng th·ª©c ch√≠nh

### `fetch_and_prepare(symbols, timeframe="1h", limit=1500, check_freshness=False) -> pd.DataFrame`

L·∫•y OHLCV data cho nhi·ªÅu symbols v√† chu·∫©n b·ªã cho deep learning.

**Tham s·ªë:**
- `symbols` (List[str]): Danh s√°ch symbols (v√≠ d·ª•: `["BTC/USDT", "ETH/USDT"]`)
- `timeframe` (str, **m·∫∑c ƒë·ªãnh**: `"1h"`): Timeframe (v√≠ d·ª•: `"1h"`, `"4h"`, `"1d"`)
- `limit` (int, **m·∫∑c ƒë·ªãnh**: `1500`): S·ªë l∆∞·ª£ng candles c·∫ßn l·∫•y
- `check_freshness` (bool, **m·∫∑c ƒë·ªãnh**: `False`): C√≥ ki·ªÉm tra ƒë·ªô t∆∞∆°i c·ªßa data kh√¥ng

**Tr·∫£ v·ªÅ:**
- `pd.DataFrame`: DataFrame ƒë√£ ƒë∆∞·ª£c preprocess v·ªõi t·∫•t c·∫£ features

**V√≠ d·ª•:**

```python
# L·∫•y data cho nhi·ªÅu symbols
df = pipeline.fetch_and_prepare(
    symbols=["BTC/USDT", "ETH/USDT", "BNB/USDT"],
    timeframe="1h",
    limit=2000
)

print(df.columns)  # Xem t·∫•t c·∫£ features ƒë√£ ƒë∆∞·ª£c t·∫°o
print(df.head())
```

### `prepare_dataframe(df, timeframe="1h") -> pd.DataFrame`

√Åp d·ª•ng full preprocessing pipeline cho m·ªôt DataFrame ƒë√£ c√≥.

**Tham s·ªë:**
- `df` (pd.DataFrame): DataFrame v·ªõi OHLCV data (ph·∫£i c√≥ columns: `open`, `high`, `low`, `close`, `volume`, `timestamp`)
- `timeframe` (str, **m·∫∑c ƒë·ªãnh**: `"1h"`): Timeframe ƒë·ªÉ t√≠nh known-future features

**Tr·∫£ v·ªÅ:**
- `pd.DataFrame`: DataFrame ƒë√£ ƒë∆∞·ª£c preprocess

**V√≠ d·ª•:**

```python
# N·∫øu ƒë√£ c√≥ DataFrame t·ª´ ngu·ªìn kh√°c
df_raw = get_data_from_other_source()

# Preprocess
df_processed = pipeline.prepare_dataframe(df_raw, timeframe="4h")
```

### `split_chronological(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, gap=None, apply_feature_selection=True, target_col="future_log_return", task_type="regression") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]`

Chia data chronologically th√†nh train/validation/test sets.

**Tham s·ªë:**
- `df` (pd.DataFrame): Preprocessed DataFrame
- `train_ratio` (float, **m·∫∑c ƒë·ªãnh**: `0.7`): T·ª∑ l·ªá training set
- `val_ratio` (float, **m·∫∑c ƒë·ªãnh**: `0.15`): T·ª∑ l·ªá validation set
- `test_ratio` (float, **m·∫∑c ƒë·ªãnh**: `0.15`): T·ª∑ l·ªá test set
- `gap` (int, **t√πy ch·ªçn**): Gap gi·ªØa train v√† val/test (m·∫∑c ƒë·ªãnh: `TARGET_HORIZON`)
- `apply_feature_selection` (bool, **m·∫∑c ƒë·ªãnh**: `True`): C√≥ √°p d·ª•ng feature selection kh√¥ng
- `target_col` (str, **m·∫∑c ƒë·ªãnh**: `"future_log_return"`): Target column name
- `task_type` (str, **m·∫∑c ƒë·ªãnh**: `"regression"`): `"regression"` ho·∫∑c `"classification"`

**Tr·∫£ v·ªÅ:**
- `Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]`: (train_df, val_df, test_df)

**V√≠ d·ª•:**

```python
# Split v·ªõi feature selection t·ª± ƒë·ªông
train_df, val_df, test_df = pipeline.split_chronological(
    df,
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    apply_feature_selection=True,
    target_col="future_log_return",
    task_type="regression"
)

print(f"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}")
```

### `apply_feature_selection(df, target_col="future_log_return", task_type="regression", symbol=None) -> pd.DataFrame`

√Åp d·ª•ng feature selection cho DataFrame ƒë√£ preprocess.

**Tham s·ªë:**
- `df` (pd.DataFrame): Preprocessed DataFrame
- `target_col` (str, **m·∫∑c ƒë·ªãnh**: `"future_log_return"`): Target column name
- `task_type` (str, **m·∫∑c ƒë·ªãnh**: `"regression"`): `"regression"` ho·∫∑c `"classification"`
- `symbol` (str, **t√πy ch·ªçn**): Symbol name cho per-symbol selection

**Tr·∫£ v·ªÅ:**
- `pd.DataFrame`: DataFrame ch·ªâ ch·ª©a selected features

**V√≠ d·ª•:**

```python
# √Åp d·ª•ng feature selection
df_selected = pipeline.apply_feature_selection(
    df,
    target_col="future_log_return",
    task_type="regression",
    symbol="BTC/USDT"
)
```

---

## C√°c th√†nh ph·∫ßn

### 1. TripleBarrierLabeler

Triple Barrier Method cho robust labeling.

**Labels:**
- `1`: Take Profit hit (profit)
- `-1`: Stop Loss hit (loss)
- `0`: Time limit reached (neutral)
- `np.nan`: Insufficient future data

**V√≠ d·ª•:**

```python
from modules.deeplearning_data_pipeline import TripleBarrierLabeler

labeler = TripleBarrierLabeler(
    tp_threshold=0.02,  # 2% TP
    sl_threshold=0.01,  # 1% SL
    time_limit=24  # 24 candles
)

df = labeler.label(df, price_col="close")
print(df["triple_barrier_label"].value_counts())
```

### 2. FractionalDifferentiator

Fractional Differentiation ƒë·ªÉ ƒë·∫£m b·∫£o stationarity m√† v·∫´n gi·ªØ memory.

**C√¥ng th·ª©c:**
```
X_t^d = sum_{k=0}^{window} (-1)^k * C(d, k) * X_{t-k}
```

**V√≠ d·ª•:**

```python
from modules.deeplearning_data_pipeline import FractionalDifferentiator

diff = FractionalDifferentiator(d=0.5, window=100)
df["close_frac_diff"] = diff.differentiate(df["close"])
```

### 3. Target Engineering

Pipeline t·ª± ƒë·ªông t·∫°o c√°c target variables:

- `log_return`: Log return gi·ªØa c√°c candles
- `pct_change`: Percentage change
- `future_log_return`: Forward-looking log return (cho prediction)
- `future_pct_change`: Forward-looking percentage change
- `triple_barrier_label`: Triple barrier label (n·∫øu enabled)

---

## V√≠ d·ª• s·ª≠ d·ª•ng

### V√≠ d·ª• 1: Basic Workflow

```python
from modules.deeplearning_data_pipeline import DeepLearningDataPipeline
from modules.DataFetcher import DataFetcher
from modules.ExchangeManager import ExchangeManager

# Setup
em = ExchangeManager()
data_fetcher = DataFetcher(em)
pipeline = DeepLearningDataPipeline(data_fetcher)

# Fetch v√† prepare
df = pipeline.fetch_and_prepare(
    symbols=["BTC/USDT"],
    timeframe="1h",
    limit=2000
)

# Split
train_df, val_df, test_df = pipeline.split_chronological(df)

print(f"Features: {len(train_df.columns)}")
print(f"Train samples: {len(train_df)}")
```

### V√≠ d·ª• 2: V·ªõi Triple Barrier

```python
# B·∫≠t triple barrier
pipeline = DeepLearningDataPipeline(
    data_fetcher=data_fetcher,
    use_triple_barrier=True,
    triple_barrier_tp=0.03,  # 3% TP
    triple_barrier_sl=0.015   # 1.5% SL
)

df = pipeline.fetch_and_prepare(symbols=["BTC/USDT"], timeframe="1h")
train_df, val_df, test_df = pipeline.split_chronological(
    df,
    target_col="triple_barrier_label",  # D√πng triple barrier label
    task_type="classification"
)
```

### V√≠ d·ª• 3: Multi-asset Training

```python
# Fetch nhi·ªÅu symbols
df = pipeline.fetch_and_prepare(
    symbols=["BTC/USDT", "ETH/USDT", "BNB/USDT", "SOL/USDT"],
    timeframe="4h",
    limit=1500
)

# Split (normalization ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng per symbol)
train_df, val_df, test_df = pipeline.split_chronological(df)

# Ki·ªÉm tra per symbol
for symbol in df["symbol"].unique():
    symbol_train = train_df[train_df["symbol"] == symbol]
    print(f"{symbol}: {len(symbol_train)} samples")
```

### V√≠ d·ª• 4: T√πy ch·ªânh Feature Selection

```python
# T√πy ch·ªânh feature selection
pipeline = DeepLearningDataPipeline(
    data_fetcher=data_fetcher,
    use_feature_selection=True,
    feature_selection_method="boruta",
    feature_selection_top_k=30,
    feature_collinearity_threshold=0.8
)

df = pipeline.fetch_and_prepare(symbols=["BTC/USDT"])
train_df, val_df, test_df = pipeline.split_chronological(df)

# Xem selected features
if pipeline.feature_selector:
    print(f"Selected {len(pipeline.feature_selector.selected_features)} features")
    print(pipeline.feature_selector.selected_features)
```

---

## Best Practices

### 1. Data Quality

- **Ki·ªÉm tra data tr∆∞·ªõc khi split:**
```python
df = pipeline.fetch_and_prepare(symbols=["BTC/USDT"])
print(df.isna().sum())  # Ki·ªÉm tra missing values
print(df.describe())     # Ki·ªÉm tra statistics
```

### 2. Normalization

- Normalization ƒë∆∞·ª£c √°p d·ª•ng **per symbol** t·ª± ƒë·ªông
- Scaler parameters ƒë∆∞·ª£c l∆∞u v√†o `artifacts/deep/scalers/`
- C√≥ th·ªÉ load l·∫°i b·∫±ng `pipeline.load_scaler(symbol)`

### 3. Feature Selection

- Feature selection ƒë∆∞·ª£c √°p d·ª•ng tr√™n **training set** only
- K·∫øt qu·∫£ ƒë∆∞·ª£c √°p d·ª•ng cho validation v√† test sets
- Selection ƒë∆∞·ª£c l∆∞u ƒë·ªÉ t√°i s·ª≠ d·ª•ng

### 4. Chronological Split

- **Lu√¥n d√πng chronological split** cho time series
- Gap ƒë∆∞·ª£c t·ª± ƒë·ªông th√™m ƒë·ªÉ tr√°nh data leakage
- Gap = `TARGET_HORIZON` (m·∫∑c ƒë·ªãnh 24 candles)

### 5. Multi-asset Training

- Pipeline h·ªó tr·ª£ multi-asset training
- Normalization per symbol ƒë·∫£m b·∫£o scale consistency
- Feature selection c√≥ th·ªÉ per-symbol ho·∫∑c global

---

## Pipeline Steps

Pipeline th·ª±c hi·ªán c√°c b∆∞·ªõc sau (trong `prepare_dataframe()`):

### Step 1: Target Engineering
- T√≠nh `log_return`, `pct_change`
- T√≠nh `future_log_return`, `future_pct_change`
- √Åp d·ª•ng Triple Barrier Method (n·∫øu enabled)

### Step 2: Fractional Differentiation
- √Åp d·ª•ng cho price columns (`open`, `high`, `low`, `close`)
- T·∫°o columns: `{col}_frac_diff`

### Step 3: Technical Indicators
- S·ª≠ d·ª•ng IndicatorEngine v·ªõi `DEEP_LEARNING` profile
- Th√™m volatility metrics (`volatility_20`, `volatility_50`)

### Step 4: Known-future Features
- Time-of-day: `hour_sin`, `hour_cos`
- Day-of-week: `day_sin`, `day_cos`
- Day-of-month: `day_of_month_sin`, `day_of_month_cos`
- Funding schedule: `hours_to_funding`, `is_funding_time`
- Candle index: `candle_index`

### Step 5: Normalization
- Per-symbol StandardScaler
- L∆∞u scaler parameters
- Exclude: targets, labels, timestamps, cyclical features

### Step 6: Feature Selection (trong split_chronological)
- √Åp d·ª•ng tr√™n training set
- L∆∞u k·∫øt qu·∫£
- √Åp d·ª•ng cho validation v√† test sets

---

## Configuration

C√°c config constants trong `modules/config.py`:

```python
# Triple Barrier
DEEP_TRIPLE_BARRIER_TP_THRESHOLD = 0.02  # 2%
DEEP_TRIPLE_BARRIER_SL_THRESHOLD = 0.01  # 1%

# Fractional Differentiation
DEEP_FRACTIONAL_DIFF_D = 0.5
DEEP_FRACTIONAL_DIFF_WINDOW = 100
DEEP_USE_FRACTIONAL_DIFF = True

# Feature Selection
DEEP_USE_FEATURE_SELECTION = True
DEEP_FEATURE_SELECTION_METHOD = "mutual_info"
DEEP_FEATURE_SELECTION_TOP_K = 25
DEEP_FEATURE_COLLINEARITY_THRESHOLD = 0.85

# Data Split
DEEP_TRAIN_RATIO = 0.7
DEEP_VAL_RATIO = 0.15
DEEP_TEST_RATIO = 0.15
```

---

## Troubleshooting

### L·ªói: "No data fetched for any symbol"

**Nguy√™n nh√¢n:** Kh√¥ng fetch ƒë∆∞·ª£c data t·ª´ b·∫•t k·ª≥ symbol n√†o

**Gi·∫£i ph√°p:**
- Ki·ªÉm tra k·∫øt n·ªëi internet
- Ki·ªÉm tra symbol names (format: `"BTC/USDT"`)
- Ki·ªÉm tra ExchangeManager c√≥ ho·∫°t ƒë·ªông kh√¥ng

### L·ªói: "Target column not found"

**Nguy√™n nh√¢n:** Target column kh√¥ng t·ªìn t·∫°i trong DataFrame

**Gi·∫£i ph√°p:**
- Ki·ªÉm tra `target_col` parameter
- ƒê·∫£m b·∫£o ƒë√£ g·ªçi `prepare_dataframe()` tr∆∞·ªõc
- V·ªõi triple barrier, d√πng `"triple_barrier_label"`

### Normalization issues

**Nguy√™n nh√¢n:** NaN values sau normalization

**Gi·∫£i ph√°p:**
- Ki·ªÉm tra data quality tr∆∞·ªõc normalization
- ƒê·∫£m b·∫£o c√≥ ƒë·ªß data per symbol
- Ki·ªÉm tra c√≥ constant columns kh√¥ng

---

## Tham kh·∫£o

- [Temporal Fusion Transformer Paper](https://arxiv.org/abs/1912.09363)
- [Fractional Differentiation](https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086)
- [Triple Barrier Method](https://www.quantresearch.org/TripleBarrierMethod.pdf)

